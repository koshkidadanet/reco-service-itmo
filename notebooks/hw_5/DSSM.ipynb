{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nIvea4cKCXzT",
   "metadata": {
    "id": "nIvea4cKCXzT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koshkidadanet/My Files/reco-service-itmo/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import requests\n",
    "import zipfile\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "from collections import Counter\n",
    "from rectools import Columns\n",
    "from rectools.dataset import Dataset as RTDataset\n",
    "from rectools.metrics import calc_metrics, NDCG, MAP, MeanInvUserFreq\n",
    "from rectools.models import model_from_config\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ZnOFxHbtEODv",
   "metadata": {
    "id": "ZnOFxHbtEODv"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename='training.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef7a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_RECOS = 10\n",
    "RANDOM_STATE = 49\n",
    "NUM_THREADS = 0\n",
    "map10 = MAP(k=K_RECOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B4yf6x5jC4Bo",
   "metadata": {
    "id": "B4yf6x5jC4Bo"
   },
   "source": [
    "# Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2cde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = os.environ.get(\"DATA_PATH\")\n",
    "\n",
    "# def download_and_extract():\n",
    "#     url = 'https://github.com/irsafilo/KION_DATASET/raw/f69775be31fa5779907cf0a92ddedb70037fb5ae/data_original.zip'\n",
    "#     filename = 'kion_train.zip'\n",
    "\n",
    "#     response = requests.get(url, stream=True)\n",
    "#     with open(filename, 'wb') as f:\n",
    "#         total = int(response.headers.get('content-length', 0))\n",
    "#         progress = tqdm(response.iter_content(1024 * 1024),\n",
    "#                         f\"Downloading {filename}\",\n",
    "#                         total=total // (1024 * 1024), unit='MB')\n",
    "#         for chunk in progress:\n",
    "#             f.write(chunk)\n",
    "\n",
    "#     with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#         zip_ref.extractall(\"../../data\")\n",
    "#     os.remove(filename)\n",
    "\n",
    "# download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "CmKM_xZICxUA",
   "metadata": {
    "id": "CmKM_xZICxUA"
   },
   "outputs": [],
   "source": [
    "data_path = os.environ.get(\"DATA_PATH\")\n",
    "\n",
    "if data_path is None:\n",
    "    data_path = \"../../data/data_original\"  # ваш путь к данным до папки data_original включительно\n",
    "\n",
    "interactions_df = (\n",
    "    pd.read_csv(os.path.join(data_path, \"interactions.csv\"), parse_dates=[\"last_watch_dt\"])\n",
    "    .rename(columns={'last_watch_dt': Columns.Datetime, 'watched_pct': Columns.Weight})\n",
    ")\n",
    "users_df = pd.read_csv(os.path.join(data_path, \"users.csv\"))\n",
    "items_df = pd.read_csv(os.path.join(data_path, \"items.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f7bddf",
   "metadata": {},
   "source": [
    "## Тренировочная и тестовая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503708bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DAYS = 7\n",
    "\n",
    "max_date = interactions_df['datetime'].max()\n",
    "train_interactions = interactions_df[(interactions_df['datetime'] <= max_date - pd.Timedelta(days=N_DAYS))]\n",
    "test_interactions = interactions_df[(interactions_df['datetime'] > max_date - pd.Timedelta(days=N_DAYS))]\n",
    "\n",
    "cold_users = set(test_interactions[Columns.User].unique()) - set(train_interactions[Columns.User])\n",
    "\n",
    "test_interactions = test_interactions[~test_interactions[Columns.User].isin(cold_users)]\n",
    "hot_users = test_interactions[Columns.User].unique()\n",
    "\n",
    "rt_dataset = RTDataset.construct(test_interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cy6gF-cSDJSn",
   "metadata": {
    "id": "cy6gF-cSDJSn"
   },
   "source": [
    "# Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c8304f",
   "metadata": {},
   "source": [
    "## Фильтрация\n",
    "- Если не фильтровать пользователей и фильмы по количеству взаимодействий, то lightfm работает намного лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c7dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N users before: 906071\n",
      "N items before: 15577\n",
      "\n",
      "N users after: 231872\n",
      "N items after: 12029\n"
     ]
    }
   ],
   "source": [
    "print(f\"N users before: {train_interactions.user_id.nunique()}\")\n",
    "print(f\"N items before: {train_interactions.item_id.nunique()}\\n\")\n",
    "\n",
    "train_interactions = train_interactions.dropna(subset='weight')\n",
    "\n",
    "# соберем всех пользователей, которые посмотрели\n",
    "# больше 5 фильмов (можете выбрать другой порог)\n",
    "valid_users = []\n",
    "\n",
    "c = Counter(train_interactions.user_id)\n",
    "for user_id, entries in c.most_common():\n",
    "    if entries > 5:\n",
    "        valid_users.append(user_id)\n",
    "\n",
    "# и соберем все фильмы, которые посмотрели больше 10 пользователей\n",
    "valid_items = []\n",
    "\n",
    "c = Counter(train_interactions.item_id)\n",
    "for item_id, entries in c.most_common():\n",
    "    if entries > 10:\n",
    "        valid_items.append(item_id)\n",
    "\n",
    "# отбросим непопулярные фильмы и неактивных юзеров\n",
    "train_interactions = train_interactions[\n",
    "    (train_interactions.user_id.isin(valid_users))\n",
    "    & (train_interactions.item_id.isin(valid_items))\n",
    "    | (train_interactions.user_id.isin(hot_users))\n",
    "]\n",
    "\n",
    "users_df = users_df[users_df.user_id.isin(train_interactions.user_id.unique())]\n",
    "train_interactions = train_interactions[train_interactions.user_id.isin(users_df.user_id.unique())]\n",
    "items_df = items_df[items_df.item_id.isin(train_interactions.item_id.unique())]\n",
    "\n",
    "print(f\"N users after: {train_interactions.user_id.nunique()}\")\n",
    "print(f\"N items after: {train_interactions.item_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59289a7",
   "metadata": {},
   "source": [
    "## Кодирование категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2b3e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age_age_18_24</th>\n",
       "      <th>age_age_25_34</th>\n",
       "      <th>age_age_35_44</th>\n",
       "      <th>age_age_45_54</th>\n",
       "      <th>age_age_55_64</th>\n",
       "      <th>age_age_65_inf</th>\n",
       "      <th>income_income_0_20</th>\n",
       "      <th>income_income_150_inf</th>\n",
       "      <th>income_income_20_40</th>\n",
       "      <th>income_income_40_60</th>\n",
       "      <th>income_income_60_90</th>\n",
       "      <th>income_income_90_150</th>\n",
       "      <th>sex_Ж</th>\n",
       "      <th>sex_М</th>\n",
       "      <th>kids_flg_0</th>\n",
       "      <th>kids_flg_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>846063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age_age_18_24  age_age_25_34  age_age_35_44  age_age_45_54  \\\n",
       "1   962099              1              0              0              0   \n",
       "3   721985              0              0              0              1   \n",
       "4   704055              0              0              1              0   \n",
       "8   846063              0              0              1              0   \n",
       "9   401219              0              0              1              0   \n",
       "\n",
       "   age_age_55_64  age_age_65_inf  income_income_0_20  income_income_150_inf  \\\n",
       "1              0               0                   0                      0   \n",
       "3              0               0                   0                      0   \n",
       "4              0               0                   0                      0   \n",
       "8              0               0                   0                      0   \n",
       "9              0               0                   0                      0   \n",
       "\n",
       "   income_income_20_40  income_income_40_60  income_income_60_90  \\\n",
       "1                    1                    0                    0   \n",
       "3                    1                    0                    0   \n",
       "4                    0                    0                    1   \n",
       "8                    0                    1                    0   \n",
       "9                    0                    1                    0   \n",
       "\n",
       "   income_income_90_150  sex_Ж  sex_М  kids_flg_0  kids_flg_1  \n",
       "1                     0      0      1           1           0  \n",
       "3                     0      1      0           1           0  \n",
       "4                     0      1      0           1           0  \n",
       "8                     0      1      0           0           1  \n",
       "9                     0      1      0           1           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "user_cat_feats = [\"age\", \"income\", \"sex\", \"kids_flg\"]\n",
    "# из исходного датафрейма оставим только item_id - этот признак нам понадобится позже\n",
    "# для того, чтобы маппить айтемы из датафрейма с фильмами с айтемами\n",
    "# из датафрейма с взаимодействиями\n",
    "users_ohe_df = users_df.user_id\n",
    "for feat in user_cat_feats:\n",
    "    # получаем датафрейм с one-hot encoding для каждой категориальной фичи\n",
    "    ohe_feat_df = pd.get_dummies(users_df[feat], prefix=feat)\n",
    "    # конкатенируем ohe-hot датафрейм с датафреймом,\n",
    "    # который мы получили на предыдущем шаге\n",
    "    users_ohe_df = pd.concat([users_ohe_df, ohe_feat_df], axis=1)\n",
    "\n",
    "users_ohe_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c975919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>content_type_film</th>\n",
       "      <th>content_type_series</th>\n",
       "      <th>for_kids_0.0</th>\n",
       "      <th>for_kids_1.0</th>\n",
       "      <th>age_rating_0.0</th>\n",
       "      <th>age_rating_6.0</th>\n",
       "      <th>age_rating_12.0</th>\n",
       "      <th>age_rating_16.0</th>\n",
       "      <th>age_rating_18.0</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_фантастика</th>\n",
       "      <th>genre_фильмы</th>\n",
       "      <th>genre_фильмы hbo</th>\n",
       "      <th>genre_фитнес</th>\n",
       "      <th>genre_футбол</th>\n",
       "      <th>genre_фэнтези</th>\n",
       "      <th>genre_хочу всё знать</th>\n",
       "      <th>genre_шоу</th>\n",
       "      <th>genre_экранизации</th>\n",
       "      <th>genre_юмор</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7868</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16268</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1468</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 836 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  content_type_film  content_type_series  for_kids_0.0  \\\n",
       "0    10711                  1                    0             0   \n",
       "2    10716                  1                    0             0   \n",
       "3     7868                  1                    0             0   \n",
       "4    16268                  1                    0             0   \n",
       "6     1468                  1                    0             0   \n",
       "\n",
       "   for_kids_1.0  age_rating_0.0  age_rating_6.0  age_rating_12.0  \\\n",
       "0             0               0               0                0   \n",
       "2             0               0               0                0   \n",
       "3             0               0               0                0   \n",
       "4             0               0               0                1   \n",
       "6             0               0               1                0   \n",
       "\n",
       "   age_rating_16.0  age_rating_18.0  ...  genre_фантастика  genre_фильмы  \\\n",
       "0                1                0  ...                 0             0   \n",
       "2                1                0  ...                 0             0   \n",
       "3                1                0  ...                 0             0   \n",
       "4                0                0  ...                 0             0   \n",
       "6                0                0  ...                 0             1   \n",
       "\n",
       "   genre_фильмы hbo  genre_фитнес  genre_футбол  genre_фэнтези  \\\n",
       "0                 0             0             0              0   \n",
       "2                 0             0             0              0   \n",
       "3                 0             0             0              0   \n",
       "4                 0             0             0              0   \n",
       "6                 0             0             0              0   \n",
       "\n",
       "   genre_хочу всё знать  genre_шоу  genre_экранизации  genre_юмор  \n",
       "0                     0          0                  0           0  \n",
       "2                     0          0                  0           0  \n",
       "3                     0          0                  0           0  \n",
       "4                     0          0                  0           0  \n",
       "6                     0          0                  0           0  \n",
       "\n",
       "[5 rows x 836 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_cat_feats = [\n",
    "    'content_type',\n",
    "    'for_kids', 'age_rating',\n",
    "    'studios', 'countries'\n",
    "]\n",
    "items_ohe_df = items_df.item_id\n",
    "\n",
    "for feat in item_cat_feats:\n",
    "    ohe_feat_df = pd.get_dummies(items_df[feat], prefix=feat)\n",
    "    items_ohe_df = pd.concat([items_ohe_df, ohe_feat_df], axis=1)\n",
    "\n",
    "genre_dummies = items_df['genres'].str.get_dummies(sep=',')\n",
    "genre_dummies.columns = ['genre_' + col for col in genre_dummies.columns]\n",
    "\n",
    "items_ohe_df = pd.concat(\n",
    "    [items_ohe_df, genre_dummies], axis=1\n",
    ")\n",
    "\n",
    "items_ohe_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f997d6c",
   "metadata": {},
   "source": [
    "## Вес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671cb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 20\n",
    "train_interactions['weight'] = pd.cut(train_interactions['weight'], bins=n_bins+1, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91718277",
   "metadata": {},
   "source": [
    "## Тест lightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b9354d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>962099</td>\n",
       "      <td>1</td>\n",
       "      <td>age_age_18_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>721985</td>\n",
       "      <td>0</td>\n",
       "      <td>age_age_18_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704055</td>\n",
       "      <td>0</td>\n",
       "      <td>age_age_18_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>846063</td>\n",
       "      <td>0</td>\n",
       "      <td>age_age_18_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401219</td>\n",
       "      <td>0</td>\n",
       "      <td>age_age_18_24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  value        feature\n",
       "1  962099      1  age_age_18_24\n",
       "3  721985      0  age_age_18_24\n",
       "4  704055      0  age_age_18_24\n",
       "8  846063      0  age_age_18_24\n",
       "9  401219      0  age_age_18_24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>value</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10711</td>\n",
       "      <td>1</td>\n",
       "      <td>content_type_film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10716</td>\n",
       "      <td>1</td>\n",
       "      <td>content_type_film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7868</td>\n",
       "      <td>1</td>\n",
       "      <td>content_type_film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16268</td>\n",
       "      <td>1</td>\n",
       "      <td>content_type_film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1468</td>\n",
       "      <td>1</td>\n",
       "      <td>content_type_film</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  value            feature\n",
       "0  10711      1  content_type_film\n",
       "2  10716      1  content_type_film\n",
       "3   7868      1  content_type_film\n",
       "4  16268      1  content_type_film\n",
       "6   1468      1  content_type_film"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_features_frames = []\n",
    "for feature in users_ohe_df.drop('user_id', axis=1).columns:\n",
    "    feature_frame = users_ohe_df.reindex(columns=[Columns.User, feature])\n",
    "    feature_frame.columns = [\"id\", \"value\"]\n",
    "    feature_frame[\"feature\"] = feature\n",
    "    user_features_frames.append(feature_frame)\n",
    "user_features_lfm = pd.concat(user_features_frames)\n",
    "display(user_features_lfm.head())\n",
    "\n",
    "item_features_frames = []\n",
    "for feature in items_ohe_df.drop('item_id', axis=1).columns:\n",
    "    feature_frame = items_ohe_df.reindex(columns=[Columns.Item, feature])\n",
    "    feature_frame.columns = [\"id\", \"value\"]\n",
    "    feature_frame[\"feature\"] = feature\n",
    "    item_features_frames.append(feature_frame)\n",
    "item_features_lfm = pd.concat(item_features_frames)\n",
    "display(item_features_lfm.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abee0b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05360831868598573\n"
     ]
    }
   ],
   "source": [
    "dataset_with_features = RTDataset.construct(\n",
    "    interactions_df=train_interactions,\n",
    "    user_features_df=user_features_lfm,\n",
    "    cat_user_features=users_ohe_df.drop('user_id', axis=1).columns.to_list(),\n",
    "    item_features_df=item_features_lfm,\n",
    "    cat_item_features=items_ohe_df.drop('item_id', axis=1).columns.to_list(),\n",
    ")\n",
    "\n",
    "config = {\n",
    "    'cls': 'LightFMWrapperModel',\n",
    "    'model': {\n",
    "        'no_components': 4,\n",
    "        'loss': 'warp',\n",
    "        'random_state': 42\n",
    "    }\n",
    "}\n",
    "\n",
    "model = model_from_config(config)\n",
    "model.fit(dataset_with_features)\n",
    "\n",
    "recos = model.recommend(\n",
    "    users=hot_users,\n",
    "    dataset=dataset_with_features,\n",
    "    k=K_RECOS,\n",
    "    filter_viewed=True,\n",
    ")\n",
    "\n",
    "print(map10.calc(recos, test_interactions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vFuyLOcZHKrl",
   "metadata": {
    "id": "vFuyLOcZHKrl"
   },
   "source": [
    "## Маппинг uid и iid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "YgXSmMmhGvWW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "id": "YgXSmMmhGvWW",
    "outputId": "ac1baa98-a20b-4c2a-e596-5345334df26b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>total_dur</th>\n",
       "      <th>weight</th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>176549</td>\n",
       "      <td>9506</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>4250</td>\n",
       "      <td>15</td>\n",
       "      <td>37320</td>\n",
       "      <td>6899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699317</td>\n",
       "      <td>1659</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>8317</td>\n",
       "      <td>20</td>\n",
       "      <td>147692</td>\n",
       "      <td>1223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>864613</td>\n",
       "      <td>7638</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>14483</td>\n",
       "      <td>20</td>\n",
       "      <td>182889</td>\n",
       "      <td>5544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1016458</td>\n",
       "      <td>354</td>\n",
       "      <td>2021-08-14</td>\n",
       "      <td>1672</td>\n",
       "      <td>5</td>\n",
       "      <td>214580</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>884009</td>\n",
       "      <td>693</td>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>703</td>\n",
       "      <td>2</td>\n",
       "      <td>186918</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id   datetime  total_dur  weight     uid   iid\n",
       "0   176549     9506 2021-05-11       4250      15   37320  6899\n",
       "1   699317     1659 2021-05-29       8317      20  147692  1223\n",
       "3   864613     7638 2021-07-05      14483      20  182889  5544\n",
       "6  1016458      354 2021-08-14       1672       5  214580   262\n",
       "7   884009      693 2021-08-04        703       2  186918   513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interactions[\"uid\"] = train_interactions[\"user_id\"].astype(\"category\")\n",
    "train_interactions[\"uid\"] = train_interactions[\"uid\"].cat.codes\n",
    "\n",
    "train_interactions[\"iid\"] = train_interactions[\"item_id\"].astype(\"category\")\n",
    "train_interactions[\"iid\"] = train_interactions[\"iid\"].cat.codes\n",
    "\n",
    "print(sorted(train_interactions.iid.unique())[:5])\n",
    "print(sorted(train_interactions.uid.unique())[:5])\n",
    "train_interactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "SgkeAjKHK4mj",
   "metadata": {
    "id": "SgkeAjKHK4mj"
   },
   "outputs": [],
   "source": [
    "iid_to_item_id = train_interactions[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"iid\").to_dict()[\"item_id\"]\n",
    "item_id_to_iid = train_interactions[[\"iid\", \"item_id\"]].drop_duplicates().set_index(\"item_id\").to_dict()[\"iid\"]\n",
    "\n",
    "uid_to_user_id = train_interactions[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"uid\").to_dict()[\"user_id\"]\n",
    "user_id_to_uid = train_interactions[[\"uid\", \"user_id\"]].drop_duplicates().set_index(\"user_id\").to_dict()[\"uid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb72da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_ohe_df[\"iid\"] = items_ohe_df[\"item_id\"].map(item_id_to_iid)\n",
    "items_ohe_df = items_ohe_df.set_index(\"iid\")\n",
    "\n",
    "users_ohe_df[\"uid\"] = users_ohe_df[\"user_id\"].map(user_id_to_uid)\n",
    "users_ohe_df = users_ohe_df.set_index(\"uid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "E75z4WRTIUd1",
   "metadata": {
    "id": "E75z4WRTIUd1"
   },
   "source": [
    "# Матрица взаимодействий\n",
    "- Формируем матрицу user на item, помечаем единичками взаимодейсвия\n",
    "- Считаем, сколько у каждого пользователя было взаимодействий\n",
    "- Для каждого пользователя делим его единички на количество его взаимодействий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ZF7CqKVOHP8i",
   "metadata": {
    "id": "ZF7CqKVOHP8i"
   },
   "outputs": [],
   "source": [
    "train_interactions_vec = np.zeros(\n",
    "    (train_interactions.uid.nunique(), train_interactions.iid.nunique())\n",
    ")\n",
    "\n",
    "for user_id, item_id in zip(train_interactions.uid, train_interactions.iid):\n",
    "    train_interactions_vec[user_id, item_id] += 1\n",
    "\n",
    "res = train_interactions_vec.sum(axis=1)\n",
    "for i in range(len(train_interactions_vec)):\n",
    "    train_interactions_vec[i] /= res[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "va_zm20pIesL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "va_zm20pIesL",
    "outputId": "27f758e5-2c9b-40fc-e272-3fa8ed484850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12029\n",
      "12029\n",
      "231872\n",
      "231872\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(train_interactions.item_id.nunique())\n",
    "print(items_ohe_df.item_id.nunique())\n",
    "print(train_interactions.user_id.nunique())\n",
    "print(users_ohe_df.user_id.nunique())\n",
    "\n",
    "print(set(items_ohe_df.item_id.unique()) - set(train_interactions.item_id.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7UWZBricDl_h",
   "metadata": {
    "id": "7UWZBricDl_h"
   },
   "source": [
    "# Основные параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "oPc_uuSmDlCM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPc_uuSmDlCM",
    "outputId": "e305e28a-9c70-4adc-c74d-9d9d59acc888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_FACTORS: 128\n",
      "ITEM_MODEL_SHAPE: (835,)\n",
      "USER_META_MODEL_SHAPE: (16,)\n",
      "USER_INTERACTION_MODEL_SHAPE: (12029,)\n"
     ]
    }
   ],
   "source": [
    "N_FACTORS = 128\n",
    "\n",
    "# в датасетах есть столбец user_id/item_id, помним, что он не является фичей для обучения!\n",
    "ITEM_MODEL_SHAPE = (items_ohe_df.drop([\"item_id\"], axis=1).shape[1], )\n",
    "USER_META_MODEL_SHAPE = (users_ohe_df.drop([\"user_id\"], axis=1).shape[1], )\n",
    "\n",
    "USER_INTERACTION_MODEL_SHAPE = (train_interactions_vec.shape[1], )\n",
    "\n",
    "print(f\"N_FACTORS: {N_FACTORS}\")\n",
    "print(f\"ITEM_MODEL_SHAPE: {ITEM_MODEL_SHAPE}\")\n",
    "print(f\"USER_META_MODEL_SHAPE: {USER_META_MODEL_SHAPE}\")\n",
    "print(f\"USER_INTERACTION_MODEL_SHAPE: {USER_INTERACTION_MODEL_SHAPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n6f9ESp4DtSV",
   "metadata": {
    "id": "n6f9ESp4DtSV"
   },
   "source": [
    "# DSSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JeEfOLCnEfM0",
   "metadata": {
    "id": "JeEfOLCnEfM0"
   },
   "source": [
    "## Инициализация модели и датасета\n",
    "\n",
    "[Про архитектуры](https://chatgpt.com/share/680411a3-b470-8004-99b8-2fbb0ac042f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JNPuhSMsDsuG",
   "metadata": {
    "id": "JNPuhSMsDsuG"
   },
   "outputs": [],
   "source": [
    "# Начальная архитектура\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, n_factors)\n",
    "        self.fc3 = nn.Linear(n_factors, n_factors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = x + torch.relu(self.fc2(x)) # residual connection\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.fc1_meta = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
    "        self.fc2_meta = nn.Linear(n_factors, n_factors)\n",
    "        self.fc1_interaction = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
    "        self.fc3 = nn.Linear(n_factors * 2, n_factors)\n",
    "\n",
    "    def forward(self, meta, interaction):\n",
    "        meta = torch.relu(self.fc1_meta(meta))\n",
    "        meta = torch.relu(self.fc2_meta(meta))\n",
    "        meta = meta + torch.relu(self.fc2_meta(meta)) # residual connection\n",
    "        interaction = torch.relu(self.fc1_interaction(interaction))\n",
    "        x = torch.cat([meta, interaction], dim=1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Трансформер, BatchNorm1d, dropout\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn1 = nn.BatchNorm1d(n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Легкий TransformerEncoderLayer\n",
    "        self.transformer = nn.TransformerEncoderLayer(\n",
    "            d_model=n_factors, nhead=2, dim_feedforward=n_factors, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.fc3 = nn.Linear(n_factors, n_factors)\n",
    "        self.ln = nn.LayerNorm(n_factors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        # Добавим фиктивную размерность для transformer (seq_len=1)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.ln(x)\n",
    "        x = x + torch.relu(self.fc2(x)) # residual connection\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.fc1_meta = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn_meta = nn.BatchNorm1d(n_factors)\n",
    "        self.fc2_meta = nn.Linear(n_factors, n_factors)\n",
    "        self.fc1_interaction = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn_inter = nn.BatchNorm1d(n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Transformer для мета-признаков пользователя\n",
    "        self.transformer_meta = nn.TransformerEncoderLayer(\n",
    "            d_model=n_factors, nhead=2, dim_feedforward=n_factors, batch_first=True, dropout=dropout\n",
    "        )\n",
    "        self.fc3 = nn.Linear(n_factors * 2, n_factors)\n",
    "        self.ln = nn.LayerNorm(n_factors)\n",
    "\n",
    "    def forward(self, meta, interaction):\n",
    "        meta = torch.relu(self.bn_meta(self.fc1_meta(meta)))\n",
    "        meta = self.dropout(meta)\n",
    "        meta = torch.relu(self.fc2_meta(meta))\n",
    "        meta = meta.unsqueeze(1)\n",
    "        meta = self.transformer_meta(meta)\n",
    "        meta = meta.squeeze(1)\n",
    "        meta = self.ln(meta)\n",
    "        meta = meta + torch.relu(self.fc2_meta(meta)) # residual connection\n",
    "        interaction = torch.relu(self.bn_inter(self.fc1_interaction(interaction)))\n",
    "        interaction = self.dropout(interaction)\n",
    "        x = torch.cat([meta, interaction], dim=1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Добавил BatchNorm1d, Dropou, убрал TransformerEncoderLayer\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn1 = nn.BatchNorm1d(n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(n_factors, n_factors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = x + torch.relu(self.fc2(x)) # residual connection\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.fc1_meta = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn_meta = nn.BatchNorm1d(n_factors)\n",
    "        self.fc2_meta = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1_interaction = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
    "        self.bn_inter = nn.BatchNorm1d(n_factors)\n",
    "        self.fc2_inter = nn.Linear(n_factors, n_factors)\n",
    "        self.fc3 = nn.Linear(n_factors * 2, n_factors)\n",
    "\n",
    "    def forward(self, meta, interaction):\n",
    "        meta = torch.relu(self.bn_meta(self.fc1_meta(meta)))\n",
    "        meta = self.dropout(meta)\n",
    "        meta = torch.relu(self.fc2_meta(meta))\n",
    "        meta = meta + torch.relu(self.fc2_meta(meta)) # residual connection\n",
    "        interaction = torch.relu(self.bn_inter(self.fc1_interaction(interaction)))\n",
    "        interaction = self.dropout(interaction)\n",
    "        interaction = torch.relu(self.fc2_inter(interaction))\n",
    "        x = torch.cat([meta, interaction], dim=1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Добавил LayerNorm (лучшая архитектура для tp_loss)\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln1 = nn.LayerNorm(n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(n_factors, n_factors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.ln1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = x + torch.relu(self.fc2(x)) # residual connection\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.fc1_meta = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln_meta = nn.LayerNorm(n_factors)\n",
    "        self.fc2_meta = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1_interaction = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln_inter = nn.LayerNorm(n_factors)\n",
    "        self.fc2_inter = nn.Linear(n_factors, n_factors)\n",
    "        self.fc3 = nn.Linear(n_factors * 2, n_factors)\n",
    "\n",
    "    def forward(self, meta, interaction):\n",
    "        meta = torch.relu(self.ln_meta(self.fc1_meta(meta)))\n",
    "        meta = self.dropout(meta)\n",
    "        meta = torch.relu(self.fc2_meta(meta))\n",
    "        meta = meta + torch.relu(self.fc2_meta(meta)) # residual connection\n",
    "        interaction = torch.relu(self.ln_inter(self.fc1_interaction(interaction)))\n",
    "        interaction = self.dropout(interaction)\n",
    "        interaction = torch.relu(self.fc2_inter(interaction))\n",
    "        x = torch.cat([meta, interaction], dim=1)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Добавил нормализацию для экспериментов с bpr_loss\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(ITEM_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln1 = nn.LayerNorm(n_factors)\n",
    "        self.fc2 = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(n_factors, n_factors)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.ln1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = x + torch.relu(self.fc2(x)) # residual connection\n",
    "        x = self.fc3(x)\n",
    "        x = F.normalize(x, p=2, dim=1)  # L2-нормализация\n",
    "        return x\n",
    "\n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, n_factors=N_FACTORS, dropout=0.2):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.fc1_meta = nn.Linear(USER_META_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln_meta = nn.LayerNorm(n_factors)\n",
    "        self.fc2_meta = nn.Linear(n_factors, n_factors)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1_interaction = nn.Linear(USER_INTERACTION_MODEL_SHAPE[0], n_factors)\n",
    "        self.ln_inter = nn.LayerNorm(n_factors)\n",
    "        self.fc2_inter = nn.Linear(n_factors, n_factors)\n",
    "        self.fc3 = nn.Linear(n_factors * 2, n_factors)\n",
    "\n",
    "    def forward(self, meta, interaction):\n",
    "        meta = torch.relu(self.ln_meta(self.fc1_meta(meta)))\n",
    "        meta = self.dropout(meta)\n",
    "        meta = torch.relu(self.fc2_meta(meta))\n",
    "        meta = meta + torch.relu(self.fc2_meta(meta)) # residual connection\n",
    "        interaction = torch.relu(self.ln_inter(self.fc1_interaction(interaction)))\n",
    "        interaction = self.dropout(interaction)\n",
    "        interaction = torch.relu(self.fc2_inter(interaction))\n",
    "        x = torch.cat([meta, interaction], dim=1)\n",
    "        x = self.fc3(x)\n",
    "        x = F.normalize(x, p=2, dim=1)  # L2-нормализация\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f8326",
   "metadata": {},
   "source": [
    "[Про лоссы](https://chatgpt.com/share/68048c0c-2d20-8003-81c7-c4aaa165176d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "k84DA7SmDyEC",
   "metadata": {
    "id": "k84DA7SmDyEC"
   },
   "outputs": [],
   "source": [
    "# Define the triplet loss function\n",
    "def triplet_loss(anchor, positive, negative, alpha=0.4):\n",
    "    pos_dist = torch.sum(torch.square(anchor - positive), dim=1)\n",
    "    neg_dist = torch.sum(torch.square(anchor - negative), dim=1)\n",
    "    basic_loss = pos_dist - neg_dist + alpha\n",
    "    loss = torch.max(basic_loss, torch.zeros_like(basic_loss))\n",
    "    return loss.mean()\n",
    "\n",
    "def bpr_loss(anchor, positive, negative):\n",
    "    sim_ap = torch.nn.functional.cosine_similarity(anchor, positive, dim=1)\n",
    "    sim_an = torch.nn.functional.cosine_similarity(anchor, negative, dim=1)\n",
    "    diff = sim_ap - sim_an\n",
    "    loss = 1 - torch.sigmoid(diff)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "PXN3ltb6D3tZ",
   "metadata": {
    "id": "PXN3ltb6D3tZ"
   },
   "outputs": [],
   "source": [
    "class RecSysDataset(Dataset):\n",
    "    def __init__(self, items, users, interactions, device, num_negs=10):\n",
    "        self.items = items\n",
    "        self.users = users\n",
    "        self.interactions = interactions\n",
    "        self.device = device\n",
    "        self.num_negs = num_negs\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.interactions.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = idx\n",
    "        pos_i = np.random.choice(range(self.interactions.shape[1]), p=self.interactions[uid])\n",
    "        # Просто случайные негативы (без hard negative mining)\n",
    "        neg_is = np.random.choice(range(self.interactions.shape[1]), size=self.num_negs, replace=False)\n",
    "        uid_meta = self.users.iloc[uid].values\n",
    "        uid_interaction = self.interactions[uid]\n",
    "        pos = self.items.iloc[pos_i].values\n",
    "        negs = np.stack([self.items.iloc[neg_i].values for neg_i in neg_is])\n",
    "        return (\n",
    "            torch.tensor(uid_meta, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(uid_interaction, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(pos, dtype=torch.float32).to(self.device),\n",
    "            torch.tensor(negs, dtype=torch.float32).to(self.device)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49e2a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "TYnYBYLwD8ha",
   "metadata": {
    "id": "TYnYBYLwD8ha"
   },
   "outputs": [],
   "source": [
    "# Initialize the models, optimizer, and dataset\n",
    "i2v = ItemModel().to(device)\n",
    "u2v = UserModel().to(device)\n",
    "optimizer = optim.Adam(list(i2v.parameters()) + list(u2v.parameters()), lr=0.001)\n",
    "dataset = RecSysDataset(\n",
    "    items=items_ohe_df.drop([\"item_id\"], axis=1),\n",
    "    users=users_ohe_df.drop([\"user_id\"], axis=1),\n",
    "    interactions=train_interactions_vec,\n",
    "    device=device\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cmQ9lPrhEjuW",
   "metadata": {
    "id": "cmQ9lPrhEjuW"
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbea983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 227/227 [08:14<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Epoch Loss: 0.3456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 227/227 [08:11<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Epoch Loss: 0.3191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 227/227 [08:05<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Epoch Loss: 0.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 227/227 [08:05<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Epoch Loss: 0.3111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 227/227 [07:59<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Epoch Loss: 0.3082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "torch.cuda.empty_cache()\n",
    "num_epochs = 5\n",
    "loss_fn = bpr_loss  # или bpr_loss\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        uid_meta, uid_interaction, pos, negs = batch\n",
    "        optimizer.zero_grad()\n",
    "        anchor = u2v(uid_meta, uid_interaction)  # [batch, emb]\n",
    "        positive = i2v(pos)                     # [batch, emb]\n",
    "        batch_size, num_negs, feat_dim = negs.shape\n",
    "        negative = i2v(negs.view(-1, feat_dim)).view(batch_size, num_negs, -1)  # [batch, num_negs, emb]\n",
    "        if loss_fn == triplet_loss:\n",
    "            # Для triplet_loss используем только первый негатив\n",
    "            loss = loss_fn(anchor, positive, negative[:, 0, :])\n",
    "        else:\n",
    "            # Для bpr_loss используем все негативы\n",
    "            anchor_exp = anchor.unsqueeze(1).expand(-1, num_negs, -1)    # [batch, num_negs, emb]\n",
    "            positive_exp = positive.unsqueeze(1).expand(-1, num_negs, -1)  # [batch, num_negs, emb]\n",
    "            sim_ap = torch.nn.functional.cosine_similarity(anchor_exp, positive_exp, dim=2)  # [batch, num_negs]\n",
    "            sim_an = torch.nn.functional.cosine_similarity(anchor_exp, negative, dim=2)      # [batch, num_negs]\n",
    "            diff = sim_ap - sim_an\n",
    "            loss = 1 - torch.sigmoid(diff)\n",
    "            loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "    avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    print(f\"Epoch {epoch + 1}, Average Epoch Loss: {avg_epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5a463bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(i2v.state_dict(), '../../artifacts/i2v_model_bpr_loss_norm')\n",
    "torch.save(u2v.state_dict(), '../../artifacts/u2v_model_bpr_loss_norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V84lpXs4FC2w",
   "metadata": {
    "id": "V84lpXs4FC2w"
   },
   "source": [
    "# Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2c7b190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserModel(\n",
       "  (fc1_meta): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (ln_meta): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc2_meta): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc1_interaction): Linear(in_features=12029, out_features=128, bias=True)\n",
       "  (ln_inter): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc2_inter): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка\n",
    "i2v = ItemModel().to(device)\n",
    "i2v.load_state_dict(torch.load('../../artifacts/i2v_model_bpr_loss_norm'))\n",
    "i2v.eval()\n",
    "\n",
    "u2v = UserModel().to(device)\n",
    "u2v.load_state_dict(torch.load('../../artifacts/u2v_model_bpr_loss_norm'))\n",
    "u2v.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inference ---\n",
    "def get_top_k_recommendations(\n",
    "    u2v,\n",
    "    users_meta: np.ndarray,\n",
    "    interactions_vec: np.ndarray,\n",
    "    items_vecs: torch.Tensor,\n",
    "    K: int,\n",
    "    device: torch.device,\n",
    "    user_indices: Optional[List] = None,\n",
    "    batch_size: int = 1024,\n",
    "    filter_viewed: bool = False,\n",
    "    user2train_items: Optional[Dict] = None,\n",
    "    iid_to_item_id: Optional[Dict] = None,\n",
    "    uid_to_user_id: Optional[Dict] = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute top-K recommendations for users. Returns DataFrame with columns: user_id, item_id, rank.\n",
    "    \"\"\"\n",
    "    dataset = TensorDataset(torch.tensor(users_meta, dtype=torch.float32), torch.arange(users_meta.shape[0]))\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    recos = []\n",
    "    with torch.no_grad():\n",
    "        for batch_users_meta, batch_idx in loader:\n",
    "            batch_users_meta = batch_users_meta.to(device)\n",
    "            batch_inter_idx = (\n",
    "                [user_indices[i.item()] for i in batch_idx] if user_indices is not None else batch_idx.tolist()\n",
    "            )\n",
    "            batch_users_interaction = torch.tensor(interactions_vec[batch_inter_idx], dtype=torch.float32).to(device)\n",
    "            batch_users_vec = u2v(batch_users_meta, batch_users_interaction)\n",
    "            batch_dists = torch.cdist(batch_users_vec, items_vecs)\n",
    "            batch_dists_np = batch_dists.cpu().numpy()\n",
    "            if filter_viewed:\n",
    "                assert user2train_items is not None and iid_to_item_id is not None and uid_to_user_id is not None\n",
    "                for i, idx in enumerate(batch_idx):\n",
    "                    uid = user_indices[idx.item()] if user_indices is not None else idx.item()\n",
    "                    user_id = uid_to_user_id[uid]\n",
    "                    seen_items = user2train_items.get(user_id, set())\n",
    "                    n_candidates = K + len(seen_items)\n",
    "                    reco_iids = np.argsort(batch_dists_np[i])[:n_candidates]\n",
    "                    reco_item_ids = [iid_to_item_id[iid] for iid in reco_iids]\n",
    "                    reco_new = [item for item in reco_item_ids if item not in seen_items][:K]\n",
    "                    for rank, item_id in enumerate(reco_new, 1):\n",
    "                        recos.append({\"user_id\": user_id, \"item_id\": item_id, \"rank\": rank})\n",
    "            else:\n",
    "                batch_topk = np.argsort(batch_dists_np, axis=1)[:, :K]\n",
    "                for i, idx in enumerate(batch_idx):\n",
    "                    uid = user_indices[idx.item()] if user_indices is not None else idx.item()\n",
    "                    user_id = uid_to_user_id[uid]\n",
    "                    for rank, iid in enumerate(batch_topk[i], 1):\n",
    "                        item_id = iid_to_item_id[iid]\n",
    "                        recos.append({\"user_id\": user_id, \"item_id\": item_id, \"rank\": rank})\n",
    "            del batch_users_meta, batch_users_interaction, batch_users_vec, batch_dists, batch_dists_np\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    return pd.DataFrame(recos)\n",
    "\n",
    "# --- Plotting ---\n",
    "def plot_distance_distributions(\n",
    "    u2v,\n",
    "    users_meta: np.ndarray,\n",
    "    interactions_vec: np.ndarray,\n",
    "    items_vecs: torch.Tensor,\n",
    "    user2items_ids: Dict,\n",
    "    all_item_ids: np.ndarray,\n",
    "    device: torch.device,\n",
    "    user_indices: List,\n",
    "    desc: str,\n",
    "    batch_size: int = 512,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot KDE of distances for positive (interacted) and negative (not interacted) user-item pairs.\n",
    "    \"\"\"\n",
    "    pos_distances, neg_distances = [], []\n",
    "    uids = list(user2items_ids.keys())\n",
    "    uid_to_meta_idx = {uid: idx for idx, uid in enumerate(uids)}\n",
    "    meta_indices = [uid_to_meta_idx[uid] for uid in uids]\n",
    "    users_meta_batch = users_meta[meta_indices]\n",
    "    users_inter_idx = [user_indices[idx] for idx in meta_indices]\n",
    "    users_inter_batch = interactions_vec[users_inter_idx]\n",
    "    dataset = TensorDataset(\n",
    "        torch.tensor(users_meta_batch, dtype=torch.float32), torch.tensor(users_inter_batch, dtype=torch.float32)\n",
    "    )\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    user_ptr = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_users_meta, batch_users_interaction in loader:\n",
    "            batch_users_meta = batch_users_meta.to(device)\n",
    "            batch_users_interaction = batch_users_interaction.to(device)\n",
    "            batch_users_vec = u2v(batch_users_meta, batch_users_interaction).cpu()\n",
    "            for i in range(batch_users_vec.shape[0]):\n",
    "                uid = uids[user_ptr]\n",
    "                user_vec = batch_users_vec[i].unsqueeze(0)\n",
    "                pos_iids = list(user2items_ids[uid])\n",
    "                if pos_iids:\n",
    "                    pos_item_vecs = items_vecs[pos_iids].detach().cpu()\n",
    "                    dists = torch.norm(user_vec - pos_item_vecs, dim=1).numpy()\n",
    "                    pos_distances.extend(dists.tolist())\n",
    "                neg_iids = list(set(all_item_ids) - set(pos_iids))\n",
    "                if neg_iids:\n",
    "                    neg_sample = np.random.choice(neg_iids, size=min(100, len(neg_iids)), replace=False)\n",
    "                    neg_item_vecs = items_vecs[neg_sample].detach().cpu()\n",
    "                    dists = torch.norm(user_vec - neg_item_vecs, dim=1).numpy()\n",
    "                    neg_distances.extend(dists.tolist())\n",
    "                user_ptr += 1\n",
    "            del batch_users_meta, batch_users_interaction, batch_users_vec\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.kdeplot(pos_distances, label=\"Positive (interacted)\", fill=True)\n",
    "    sns.kdeplot(neg_distances, label=\"Negative (not interacted)\", fill=True)\n",
    "    plt.xlabel(\"Distance\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"Distribution of distances: user-item (positive vs negative) [{desc}]\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# --- Data Preparation ---\n",
    "def get_users_meta_and_indices(users, users_ohe_df: pd.DataFrame) -> Tuple[List, np.ndarray]:\n",
    "    \"\"\"Return sorted user list and their meta features array.\"\"\"\n",
    "    users = sorted(users)\n",
    "    users_meta = users_ohe_df.loc[users].drop([\"user_id\"], axis=1).values\n",
    "    return users, users_meta\n",
    "\n",
    "\n",
    "def calc_metrics_(recos, interactions) -> Dict[str, float]:\n",
    "    metrics = {\n",
    "        'ndcg@10': NDCG(k=K_RECOS),\n",
    "        'map@10': MAP(k=K_RECOS),\n",
    "        'novelty@10': MeanInvUserFreq(k = K_RECOS),\n",
    "    }\n",
    "    return calc_metrics(\n",
    "        metrics=metrics,\n",
    "        reco=recos,\n",
    "        interactions=interactions,\n",
    "        prev_interactions=train_interactions,\n",
    "        catalog=train_interactions.item_id.unique()\n",
    "    )\n",
    "\n",
    "# Подготовка данных\n",
    "test_interactions_filtered = test_interactions[\n",
    "    test_interactions.user_id.isin(train_interactions.user_id.unique())\n",
    "    & test_interactions.item_id.isin(train_interactions.item_id.unique())\n",
    "]\n",
    "\n",
    "test_interactions_filtered[\"uid\"] = test_interactions_filtered[\"user_id\"].map(user_id_to_uid)\n",
    "test_interactions_filtered[\"iid\"] = test_interactions_filtered[\"item_id\"].map(item_id_to_iid)\n",
    "\n",
    "items_feats = torch.tensor(items_ohe_df.drop([\"item_id\"], axis=1).values, dtype=torch.float32).to(device)\n",
    "items_vecs = i2v(items_feats)\n",
    "\n",
    "\n",
    "# Inference: test set (all items)\n",
    "test_users, test_users_meta = get_users_meta_and_indices(test_interactions_filtered.uid.unique(), users_ohe_df)\n",
    "df_dssm_test = get_top_k_recommendations(\n",
    "    u2v,\n",
    "    test_users_meta,\n",
    "    train_interactions_vec,\n",
    "    items_vecs,\n",
    "    K_RECOS,\n",
    "    device,\n",
    "    user_indices=test_users,\n",
    "    filter_viewed=False,\n",
    "    iid_to_item_id=iid_to_item_id,\n",
    "    uid_to_user_id=uid_to_user_id,\n",
    ")\n",
    "print('Metrics on test set (all items):')\n",
    "print(calc_metrics_(df_dssm_test, test_interactions_filtered))\n",
    "\n",
    "# Inference: test set (only new items)\n",
    "user2train_items = train_interactions.groupby(\"user_id\")[\"item_id\"].apply(set).to_dict()\n",
    "df_dssm_test_new = get_top_k_recommendations(\n",
    "    u2v,\n",
    "    test_users_meta,\n",
    "    train_interactions_vec,\n",
    "    items_vecs,\n",
    "    K_RECOS,\n",
    "    device,\n",
    "    user_indices=test_users,\n",
    "    filter_viewed=True,\n",
    "    user2train_items=user2train_items,\n",
    "    iid_to_item_id=iid_to_item_id,\n",
    "    uid_to_user_id=uid_to_user_id,\n",
    ")\n",
    "print('Metrics on test set (only new items):')\n",
    "print(calc_metrics_(df_dssm_test_new, test_interactions_filtered))\n",
    "\n",
    "# Inference: all train users\n",
    "all_users, all_users_meta = get_users_meta_and_indices(train_interactions.uid.unique(), users_ohe_df)\n",
    "df_dssm = get_top_k_recommendations(\n",
    "    u2v,\n",
    "    all_users_meta,\n",
    "    train_interactions_vec,\n",
    "    items_vecs,\n",
    "    K_RECOS,\n",
    "    device,\n",
    "    user_indices=all_users,\n",
    "    filter_viewed=False,\n",
    "    iid_to_item_id=iid_to_item_id,\n",
    "    uid_to_user_id=uid_to_user_id,\n",
    ")\n",
    "print('Metrics on train set:')\n",
    "print(calc_metrics_(df_dssm, train_interactions))\n",
    "\n",
    "\n",
    "# Plotting: test\n",
    "test_user2items_ids = test_interactions_filtered.groupby(\"uid\")[\"iid\"].apply(set).to_dict()\n",
    "all_item_ids = train_interactions.iid.unique()\n",
    "plot_distance_distributions(\n",
    "    u2v,\n",
    "    test_users_meta,\n",
    "    train_interactions_vec,\n",
    "    items_vecs,\n",
    "    test_user2items_ids,\n",
    "    all_item_ids,\n",
    "    device,\n",
    "    user_indices=test_users,\n",
    "    desc=\"test\",\n",
    "    batch_size=128,\n",
    ")\n",
    "# Plotting: train\n",
    "train_user2items_ids = train_interactions.groupby(\"uid\")[\"iid\"].apply(set).to_dict()\n",
    "plot_distance_distributions(\n",
    "    u2v,\n",
    "    all_users_meta,\n",
    "    train_interactions_vec,\n",
    "    items_vecs,\n",
    "    train_user2items_ids,\n",
    "    all_item_ids,\n",
    "    device,\n",
    "    user_indices=all_users,\n",
    "    desc=\"train\",\n",
    "    batch_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045eb828",
   "metadata": {},
   "source": [
    "# Итого\n",
    "\n",
    "- Реализовал обучение и инференс на GPU\n",
    "- Разбил данные на тестовую и тренировочную метрику\n",
    "- Реализовал расчет метрик\n",
    "- Обучил lightfm для сравнения. Заметил, что без фильтрации датасета метрика на тестовой выборке намного лучше\n",
    "- Эксперименты с архитектурами `UserModel` и `ItemModel`:  \n",
    "    - Добавлены слои `BatchNorm1d` и `dropout`.\n",
    "    - Добавлен `TransformerEncoderLayer`. Сначала добавил этот слой для мета данных юзеров и айтемов, потом понял, что его нужно добавлять для вектора взаимодействий. Но после более подробного изучения понял, что вектора взаимодействий должны учитывать временную составляющу, чтобы работал механизм внимания. Задача нетривиальная, принял решение пока отказаться от использования данного слоя\n",
    "    - Добавлен этап LN, это позволило добиться наилучших результатов\n",
    "- Реализован инференс с рассчетом `MAP`, `NDCG`, `novelty` и выводом гистограмм распределения расстояний между позитивом и негативом. Инференс для тестовой выборки реализован в 2х вариантах: рекомендуем все item или рекомендуем только новые. Рекомендацию только непросмотренных item позволила улучшить метрику `MAP` и существенно улучшить `novelty`\n",
    "- Реализован BPR_loss. С этим лоссом не удалось добиться сходимости. Проводились эксперименты с архитектурой, сэмплированием негативных примеров, количеством эпох, learning_rate, размером батча. Ничего из этого не помогло, принято решение остановиться на triplet_loss\n",
    "- UPD по BPR_loss. После анализа распределения расстояний для позитивов и негативов заметил, что расстояния распределениы примерно от 50 до 255, в то время как для triplet_loss они распределены от 0.5 до 4. Накатило осознание, что нужно попробовать добавить в архитектуру L2 нормализацию для эмбеддингов при использовании bpr_loss.\n",
    "В итоге это не помогло, но распределение расстояний поменялось. Появился бугор около 0 и бугор около 2х."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9a035",
   "metadata": {},
   "source": [
    "Дропауты, триплетт лосс\n",
    "\n",
    "Metrics on test set (all items):  \n",
    "{'ndcg@10': 0.020150051921643704, 'map@10': 0.03442064385565833, 'novelty@10': 6.6893864751852234}  \n",
    "Metrics on test set (only new items):  \n",
    "{'ndcg@10': 0.022607524303127062, 'map@10': 0.040237918803309895, 'novelty@10': 7.4382998570788175}  \n",
    "Metrics on train set:  \n",
    "{'ndcg@10': 0.1528670560518531, 'map@10': 0.08338817995936873, 'novelty@10': 6.150502687035253}  \n",
    "\n",
    "![image-1.png](images/image_1.png)\n",
    "![image-2.png](images/image_2.png)\n",
    "\n",
    "Триплет лосс, дропают, LN, 5 эпох:  \n",
    "После добавления распределение расстояний на тренировочном и тестовом датасетах сместилось влево.  \n",
    "\n",
    "Metrics on test set (all items):  \n",
    "{'ndcg@10': 0.02362516138072357, 'map@10': 0.04165041467247998, 'novelty@10': 6.704579471536163}  \n",
    "Metrics on test set (only new items):  \n",
    "{'ndcg@10': 0.026416019038800274, 'map@10': 0.049272534531008376, 'novelty@10': 7.410556220576975}  \n",
    "Metrics on train set:  \n",
    "{'ndcg@10': 0.1590928053856303, 'map@10': 0.09365070823244875, 'novelty@10': 6.296392580539426}  \n",
    "\n",
    "![image-3.png](images/image_3.png)\n",
    "![image-4.png](images/image_4.png)\n",
    "\n",
    "\n",
    " \n",
    "BPR_loss  \n",
    "Metrics on test set (all items):  \n",
    "{'ndcg@10': 0.00022799403808741964, 'map@10': 0.0002336042134449884, 'novelty@10': 11.537375548766876}  \n",
    "Metrics on test set (only new items):  \n",
    "{'ndcg@10': 0.00022876025679039637, 'map@10': 0.00023424274043325845, 'novelty@10': 11.541674360437256}  \n",
    "Metrics on train set:  \n",
    "{'ndcg@10': 0.0017234810371572673, 'map@10': 0.00032141210525153517, 'novelty@10': 11.554501635683124}  \n",
    "\n",
    "![image-5.png](images/image_5.png)\n",
    "![image-6.png](images/image_6.png)\n",
    "\n",
    "BPR_loss L2_norm  \n",
    "Metrics on test set (all items):  \n",
    "{'ndcg@10': 0.004268759723329381, 'map@10': 0.007981950890367883, 'novelty@10': 10.359371160120494}  \n",
    "Metrics on test set (only new items):  \n",
    "{'ndcg@10': 0.004424605129663591, 'map@10': 0.00840846146571718, 'novelty@10': 10.507040145281902}  \n",
    "Metrics on train set:  \n",
    "{'ndcg@10': 0.026595616391652716, 'map@10': 0.014998711478326257, 'novelty@10': 10.474641643549294}  \n",
    "\n",
    "![image-7.png](images/image_7.png)\n",
    "![image-8.png](images/image_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee3a92",
   "metadata": {
    "id": "93ee3a92"
   },
   "source": [
    "# 🧠 DSSM Homework: Improve the Model\n",
    "\n",
    "Welcome! This assignment builds upon the DSSM model you studied during the seminar.\n",
    "\n",
    "Your task is to **improve the DSSM model** by modifying the architecture, loss function, evaluation, or training pipeline. This is an open-ended assignment meant to encourage exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e48b0f",
   "metadata": {
    "id": "47e48b0f"
   },
   "source": [
    "In this seminar, you've explored a basic implementation of the Deep Structured Semantic Model (DSSM).\n",
    "\n",
    "Your task is to **improve this model** in one or more of the following directions:\n",
    "\n",
    "### ✅ Model Improvements\n",
    "- Replace MLP towers with Transformer or RNN encoders or etc. (5 баллов)\n",
    "- Use different triplet loss. (3 балла) 5 21:10\n",
    "- Add dropout, batch normalization, or layer norm. (3 балла)\n",
    "- Integrate embeddings instead of one-hot vectors. (5 баллов)\n",
    "- Visualize similarity distribution for positive vs. negative pairs. (5 баллов)\n",
    "\n",
    "### ✅ Evaluation & Analysis\n",
    "- Visualize embeddings using t-SNE or UMAP. (3 баллов)\n",
    "- Develop and improve beyond accuracy metrics. (5 баллов) 1:14\n",
    "\n",
    "### 📄 Deliverables\n",
    "- Explain what you changed and why in the final markdown cell. (3 балла)\n",
    "- Keep code modular, clean, and well-documented. (3 балла)\n",
    "\n",
    "### 📝 Production\n",
    "- create service based on DSSM vectors with ANN. (8 баллов)\n",
    "\n",
    "### 📝 Leaderboard\n",
    "- Improve score from UserKNN via DSSM (8 баллов)\n",
    "\n",
    "\n",
    "Максимум баллов, которые можно получить - 25."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
